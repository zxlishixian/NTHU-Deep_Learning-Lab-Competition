{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e48d659c",
   "metadata": {},
   "source": [
    "comp4:\n",
    "\n",
    "BATCH_SIZE = 200\n",
    "TRAIN_SIZE = 26000\n",
    "VAL_SIZE = 1000\n",
    "\n",
    "# 使用改进的数据流\n",
    "TRAIN_PATH = './dataset/train.csv'\n",
    "train_stream, val_stream, train_size, val_size = get_data_streams(\n",
    "    TRAIN_PATH, train_size=TRAIN_SIZE, val_size=VAL_SIZE, batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "\n",
    "iters = int((TRAIN_SIZE + BATCH_SIZE - 1) / BATCH_SIZE)  # 向上取整\n",
    "\n",
    "\n",
    "# ========== 向量器（内存友好的 Hashing） ==========\n",
    "hashvec = HashingVectorizer(\n",
    "    n_features=2**22,                # 可按内存改 2**19~2**22\n",
    "    alternate_sign=False,            # PassiveAggressive/SVM 用非负/非负也都可以；NB 必须非负\n",
    "    ngram_range=(2,3),              # unigram+bigram\n",
    "    preprocessor=preprocessor,\n",
    "    tokenizer=tokenizer_stem_keepmeta  \n",
    ")\n",
    "\n",
    "def featurize(html_series: pd.Series) -> sp.csr_matrix:\n",
    "    \"\"\"一处封装，方便以后换成“词+字符双哈希”等更强特征。\"\"\"\n",
    "    return hashvec.transform(html_series.astype(str))\n",
    "\n",
    "# ========== 模型 ==========\n",
    "classes = np.array([0, 1])\n",
    "\n",
    "# 你现在用的是 PassiveAggressive（与文本流式很配）\n",
    "clf = SGDClassifier(\n",
    "    loss=\"hinge\",           # 或 \"hinge\"\n",
    "    penalty=\"elasticnet\",\n",
    "    alpha=1e-6,\n",
    "    l1_ratio=0.15,\n",
    "    learning_rate=1000,  # \"constant\"/\"adaptive\"/\"optimal\"/\"invscaling\"\n",
    "                         # 步长\n",
    "    average=True,\n",
    "    max_iter=1, tol=None,\n",
    "    random_state=42\n",
    "\n",
    "\n",
    "    目前最佳 0.583\n",
    "\n",
    "   eta=900 0.5940\n",
    "\n",
    "   n_features=2**23,    0.5942\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1aa542d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72d88f3d",
   "metadata": {},
   "source": [
    "# =========================\n",
    "# K 折交叉驗證 + 每折最佳模型集成輸出 test 預測\n",
    "# =========================\n",
    "import os, gc, copy, _pickle as pkl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import ceil\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from scipy.special import expit\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# ---------- 基本配置 ----------\n",
    "TRAIN_PATH = './dataset/train.csv'\n",
    "TEST_PATH  = './dataset/test.csv'\n",
    "OUT_DIR    = './output'\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "CV_MODE     = 'group'   # 'group' or 'stratified'\n",
    "N_SPLITS    = 5\n",
    "EPOCHS      = 3\n",
    "BATCH_SIZE  = 2000\n",
    "SEED        = 42\n",
    "PATIENCE    = 2         # 早停：連續 PATIENCE 個 epoch 無提升就停\n",
    "DO_FOLD_LDA = False     # True：每折在訓練集上預訓練 LDA（更穩但更慢）\n",
    "\n",
    "# ---------- 分組鍵提取（publisher） ----------\n",
    "_MONTH = dict(jan='01', feb='02', mar='03', apr='04', may='05', jun='06',\n",
    "              jul='07', aug='08', sep='09', oct='10', nov='11', dec='12')\n",
    "\n",
    "def _norm(s): return re.sub(r'[\\W]+', ' ', (s or '').lower()).strip()\n",
    "def _slug(s): return re.sub(r'[^a-z0-9_]+', '', _norm(s).replace(' ', '_'))\n",
    "\n",
    "def extract_publisher_slug(html: str) -> str:\n",
    "    if not isinstance(html, str) or not html.strip():\n",
    "        return \"unknown\"\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    pub = soup.find('a', href=re.compile(r'/publishers/[^/]+/?', re.I))\n",
    "    if pub:\n",
    "        publisher = pub.get_text(' ', strip=True) or re.sub(r'.*/publishers/([^/]+)/?.*', r'\\1', pub['href'], flags=re.I)\n",
    "    else:\n",
    "        publisher = \"unknown\"\n",
    "    return _slug(publisher or 'unknown')\n",
    "\n",
    "# ---------- 分類器工廠（文本穩定配置） ----------\n",
    "def make_clf():\n",
    "    return SGDClassifier(\n",
    "        loss=\"log_loss\",        # 用邏輯損失以獲得 predict_proba\n",
    "        penalty=\"elasticnet\",\n",
    "        alpha=1e-5,\n",
    "        l1_ratio=0.05,\n",
    "        learning_rate=\"optimal\",\n",
    "        average=True,\n",
    "        random_state=SEED\n",
    "    )\n",
    "\n",
    "# ---------- 讀取資料 ----------\n",
    "df = pd.read_csv(TRAIN_PATH)\n",
    "df['Popularity'] = (df['Popularity'].astype(int) == 1).astype(int)\n",
    "y = df['Popularity'].values\n",
    "texts = df['Page content'].astype(str)\n",
    "\n",
    "# CV split 準備\n",
    "if CV_MODE == 'group':\n",
    "    groups = texts.apply(extract_publisher_slug).values\n",
    "    splitter = GroupKFold(n_splits=N_SPLITS)\n",
    "    split_iter = splitter.split(texts, y, groups)\n",
    "    print(f\"Using GroupKFold by publisher (groups={len(np.unique(groups))})\")\n",
    "else:\n",
    "    splitter = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "    split_iter = splitter.split(texts, y)\n",
    "    print(\"Using StratifiedKFold\")\n",
    "\n",
    "# 容器\n",
    "fold_artifacts = []  # 保存每折最佳模型與（可選）LDA\n",
    "oof_scores = np.zeros(len(df), dtype=float)\n",
    "fold_aucs, fold_epochs = [], []\n",
    "\n",
    "print(f\"\\nStart {N_SPLITS}-fold CV: EPOCHS={EPOCHS}, BATCH_SIZE={BATCH_SIZE}, DO_FOLD_LDA={DO_FOLD_LDA}\")\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(split_iter, start=1):\n",
    "    print(f\"\\n========== Fold {fold}/{N_SPLITS} ==========\")\n",
    "    tr_df = df.iloc[tr_idx].reset_index(drop=True)\n",
    "    va_df = df.iloc[va_idx].reset_index(drop=True)\n",
    "    y_val = va_df['Popularity'].values\n",
    "\n",
    "    # 每折 LDA（可選，避免外洩需在訓練集上建）\n",
    "    if DO_FOLD_LDA:\n",
    "        lda_vec_f, lda_mod_f = pretrain_lda(tr_df, column='Page content', n_components=10, max_features=1000)\n",
    "    else:\n",
    "        lda_vec_f, lda_mod_f = (None, None)\n",
    "\n",
    "    # 固定本折驗證特徵\n",
    "    X_val = featurize_split(va_df['Page content'].astype(str), lda_vec_f, lda_mod_f, n_jobs=1)\n",
    "\n",
    "    # 模型與早停\n",
    "    clf = make_clf()\n",
    "    best_auc, best_epoch = -1, -1\n",
    "    best_state = None\n",
    "    no_improve = 0\n",
    "\n",
    "    # 多 epoch 訓練\n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        tr_shuf = tr_df.sample(frac=1.0, random_state=SEED+epoch).reset_index(drop=True)\n",
    "        n_batches = ceil(len(tr_shuf)/BATCH_SIZE)\n",
    "\n",
    "        for b in range(n_batches):\n",
    "            batch = tr_shuf.iloc[b*BATCH_SIZE:(b+1)*BATCH_SIZE]\n",
    "            X_tr = featurize_split(batch['Page content'].astype(str), lda_vec_f, lda_mod_f, n_jobs=1)\n",
    "            y_tr = batch['Popularity'].values\n",
    "            if epoch == 1 and b == 0:\n",
    "                clf.partial_fit(X_tr, y_tr, classes=np.array([0,1]))\n",
    "            else:\n",
    "                clf.partial_fit(X_tr, y_tr)\n",
    "\n",
    "        # epoch 結束：評估本折 Val\n",
    "        if hasattr(clf, \"predict_proba\"):\n",
    "            val_prob = clf.predict_proba(X_val)[:, 1]\n",
    "        else:\n",
    "            val_prob = expit(clf.decision_function(X_val))\n",
    "        val_auc = roc_auc_score(y_val, val_prob)\n",
    "        print(f\"Fold {fold} | epoch {epoch}/{EPOCHS} | Val AUC={val_auc:.4f}\")\n",
    "\n",
    "        if val_auc > best_auc:\n",
    "            best_auc = val_auc\n",
    "            best_epoch = epoch\n",
    "            best_state = copy.deepcopy(clf)\n",
    "            no_improve = 0\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve >= PATIENCE:\n",
    "                print(f\"  Early stopping at epoch {epoch} (no improve {PATIENCE}×)\")\n",
    "                break\n",
    "\n",
    "    # 保存 OOF（用最佳狀態）\n",
    "    if hasattr(best_state, \"predict_proba\"):\n",
    "        oof_scores[va_idx] = best_state.predict_proba(X_val)[:, 1]\n",
    "    else:\n",
    "        oof_scores[va_idx] = expit(best_state.decision_function(X_val))\n",
    "\n",
    "    fold_aucs.append(best_auc); fold_epochs.append(best_epoch)\n",
    "\n",
    "    # 保存每折最佳模型到硬碟\n",
    "    model_path = os.path.join(OUT_DIR, f'clf_sgd_fold{fold}.pkl')\n",
    "    pkl.dump(best_state, open(model_path, 'wb'))\n",
    "\n",
    "    # 若用了 LDA，順便把該折的 LDA 也存起來\n",
    "    lda_path = None\n",
    "    if DO_FOLD_LDA:\n",
    "        lda_path = os.path.join(OUT_DIR, f'lda_fold{fold}.pkl')\n",
    "        pkl.dump({'lda_vec': lda_vec_f, 'lda_model': lda_mod_f}, open(lda_path, 'wb'))\n",
    "\n",
    "    fold_artifacts.append({\n",
    "        'model_path': model_path,\n",
    "        'lda_path': lda_path\n",
    "    })\n",
    "    print(f\"Fold {fold} BEST: epoch={best_epoch}, AUC={best_auc:.4f} | saved {model_path}\")\n",
    "\n",
    "    del X_val; gc.collect()\n",
    "\n",
    "# CV 總結\n",
    "oof_auc = roc_auc_score(y, oof_scores)\n",
    "print(\"\\n========== CV Summary ==========\")\n",
    "print(\"Fold AUCs:\", [\"%.4f\" % a for a in fold_aucs])\n",
    "print(\"Mean AUC = %.4f | Std = %.4f\" % (np.mean(fold_aucs), np.std(fold_aucs)))\n",
    "print(\"OOF  AUC = %.4f\" % oof_auc)\n",
    "\n",
    "# ---------- 用每折最佳模型對 test 預測並平均 ----------\n",
    "df_test = pd.read_csv(TEST_PATH)\n",
    "test_texts = df_test['Page content'].astype(str)\n",
    "test_preds_each_fold = []\n",
    "\n",
    "for fold, art in enumerate(fold_artifacts, start=1):\n",
    "    # 讀模型\n",
    "    clf = pkl.load(open(art['model_path'], 'rb'))\n",
    "    # 讀折內 LDA（可選）\n",
    "    if DO_FOLD_LDA and art['lda_path'] is not None:\n",
    "        lda_pack = pkl.load(open(art['lda_path'], 'rb'))\n",
    "        lda_vec_f, lda_mod_f = lda_pack['lda_vec'], lda_pack['lda_model']\n",
    "    else:\n",
    "        lda_vec_f, lda_mod_f = (None, None)\n",
    "\n",
    "    # 特徵化（若各折 LDA 不同，需各自 transform 一次）\n",
    "    X_test = featurize_split(test_texts, lda_vec_f, lda_mod_f, n_jobs=1)\n",
    "\n",
    "    # 預測機率\n",
    "    if hasattr(clf, \"predict_proba\"):\n",
    "        prob = clf.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        prob = expit(clf.decision_function(X_test))\n",
    "    test_preds_each_fold.append(prob)\n",
    "    print(f\"Fold {fold} test predicted. Shape={prob.shape}\")\n",
    "\n",
    "# 集成（平均）\n",
    "test_pred = np.mean(np.vstack(test_preds_each_fold), axis=0)\n",
    "\n",
    "# 導出提交\n",
    "sub_path = os.path.join(OUT_DIR, f'submission_k{N_SPLITS}_ens.csv')\n",
    "pd.DataFrame({'Id': df_test['Id'], 'Popularity': test_pred}).to_csv(sub_path, index=False)\n",
    "print(\"Submission saved ->\", sub_path)\n",
    "\n",
    "\n",
    "目前最佳 0.584"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9429e05",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1476553",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
