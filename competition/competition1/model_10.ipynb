{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ec9d133",
   "metadata": {},
   "source": [
    "Cell 1 — Imports & Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9ed8589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================\n",
    "# Cell 1 — Imports & Config\n",
    "# =============================================\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import math\n",
    "import _pickle as pkl\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "\n",
    "# boosting libs\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "DATA_DIR = Path(\"./dataset\")\n",
    "OUT_DIR = Path(\"./output\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SUB_PATH   = OUT_DIR / \"submission_model9_mimic_model8_plus_author_publisher.csv\"\n",
    "MODEL_PATH = OUT_DIR / \"voting_model9_mimic_model8_plus_author_publisher.pkl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b15e675d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/test: (27643, 3) (11847, 2)\n"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# Cell 2 — Load Data\n",
    "# =============================================\n",
    "TRAIN_PATH = DATA_DIR / \"train.csv\"\n",
    "TEST_PATH  = DATA_DIR / \"test.csv\"\n",
    "\n",
    "assert TRAIN_PATH.exists() and TEST_PATH.exists(), \"train.csv / test.csv 未找到（应位于 ./dataset/）\"\n",
    "\n",
    "df_train = pd.read_csv(TRAIN_PATH)\n",
    "df_test  = pd.read_csv(TEST_PATH)\n",
    "\n",
    "assert {\"Id\", \"Page content\", \"Popularity\"}.issubset(df_train.columns)\n",
    "assert {\"Id\", \"Page content\"}.issubset(df_test.columns)\n",
    "\n",
    "print(\"train/test:\", df_train.shape, df_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1b8415b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Channel</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Day</th>\n",
       "      <th>Date</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>Second</th>\n",
       "      <th>Content_Len</th>\n",
       "      <th>Num_See_Also</th>\n",
       "      <th>Num_Image</th>\n",
       "      <th>Num_A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>clara moskowitz</td>\n",
       "      <td>world</td>\n",
       "      <td>topics: asteroid , asteroids , challenge , ear...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>2013</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>3787</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>christina warren</td>\n",
       "      <td>tech</td>\n",
       "      <td>topics: apps and software , google , open sour...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>2013</td>\n",
       "      <td>17</td>\n",
       "      <td>40</td>\n",
       "      <td>55</td>\n",
       "      <td>2081</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>unknown</td>\n",
       "      <td>sam laird</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>topics: entertainment , nfl , nfl draft , spor...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2014</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>6761</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>unknown</td>\n",
       "      <td>sam laird</td>\n",
       "      <td>watercooler</td>\n",
       "      <td>topics: sports , video , videos , watercooler</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>50</td>\n",
       "      <td>1751</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>unknown</td>\n",
       "      <td>connor finnegan</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>topics: entertainment , instagram , instagram ...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>43</td>\n",
       "      <td>8720</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id    Title            Author        Channel  \\\n",
       "0   0  unknown   clara moskowitz          world   \n",
       "1   1  unknown  christina warren           tech   \n",
       "2   2  unknown         sam laird  entertainment   \n",
       "3   3  unknown         sam laird    watercooler   \n",
       "4   4  unknown   connor finnegan  entertainment   \n",
       "\n",
       "                                               Topic Publisher  Day  Date  \\\n",
       "0  topics: asteroid , asteroids , challenge , ear...   unknown    3    19   \n",
       "1  topics: apps and software , google , open sour...   unknown    4    28   \n",
       "2  topics: entertainment , nfl , nfl draft , spor...   unknown    3     7   \n",
       "3      topics: sports , video , videos , watercooler   unknown    5    11   \n",
       "4  topics: entertainment , instagram , instagram ...   unknown    4    17   \n",
       "\n",
       "   Month  Year  Hour  Minute  Second  Content_Len  Num_See_Also  Num_Image  \\\n",
       "0      6  2013    15       4      30         3787             4          1   \n",
       "1      3  2013    17      40      55         2081             1          2   \n",
       "2      5  2014    19      15      20         6761             1          2   \n",
       "3     10  2013     2      26      50         1751             1          1   \n",
       "4      4  2014     3      31      43         8720             1         52   \n",
       "\n",
       "   Num_A  \n",
       "0     22  \n",
       "1     18  \n",
       "2     11  \n",
       "3     13  \n",
       "4     16  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================\n",
    "# Cell 3 — HTML parsing（mimic model8 + Publisher）\n",
    "# =============================================\n",
    "import re\n",
    "from datetime import datetime\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "def _s(x) -> str:\n",
    "    return x if isinstance(x, str) else \"\"\n",
    "\n",
    "def _clean(s: str) -> str:\n",
    "    s = (s or \"\").strip().lower()\n",
    "    return s if s else \"unknown\"\n",
    "\n",
    "# 时间解析正则（与 model8 类似的优先级：ISO → 英文月名 → 仅时间）\n",
    "_RE_ISO       = re.compile(r\"\\b(?P<y>\\d{4})[-/](?P<m>\\d{1,2})[-/](?P<d>\\d{1,2})(?:[ T](?P<H>\\d{1,2}):(?P<M>\\d{2})(?::(?P<S>\\d{2}))?)?\", re.I)\n",
    "_RE_MMM_D_Y   = re.compile(r\"\\b(?P<mon>jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec)[a-z]*[ ,.-]+(?P<d>\\d{1,2})[ ,.-]+(?P<y>\\d{4})(?:[ ,T](?P<H>\\d{1,2}):(?P<M>\\d{2})(?::(?P<S>\\d{2}))?)?\", re.I)\n",
    "_RE_HMS       = re.compile(r\"\\b(?P<H>\\d{1,2}):(?P<M>\\d{2})(?::(?P<S>\\d{2}))?\\b\")\n",
    "_MON_MAP      = {m:i for i,m in enumerate(['jan','feb','mar','apr','may','jun','jul','aug','sep','oct','nov','dec'], start=1)}\n",
    "\n",
    "def _first_datetime(text: str):\n",
    "    text = _s(text)\n",
    "\n",
    "    m = _RE_ISO.search(text)\n",
    "    if m:\n",
    "        y = int(m.group('y')); mth = int(m.group('m')); d = int(m.group('d'))\n",
    "        H = int(m.group('H')) if m.group('H') else None\n",
    "        M = int(m.group('M')) if m.group('M') else None\n",
    "        S = int(m.group('S')) if m.group('S') else None\n",
    "        return y, mth, d, H, M, S\n",
    "\n",
    "    m = _RE_MMM_D_Y.search(text)\n",
    "    if m:\n",
    "        y = int(m.group('y')); d = int(m.group('d'))\n",
    "        mmm = m.group('mon').lower()\n",
    "        mth = _MON_MAP.get(mmm, None)\n",
    "        H = int(m.group('H')) if m.group('H') else None\n",
    "        M = int(m.group('M')) if m.group('M') else None\n",
    "        S = int(m.group('S')) if m.group('S') else None\n",
    "        return y, mth, d, H, M, S\n",
    "\n",
    "    m = _RE_HMS.search(text)\n",
    "    if m:\n",
    "        H = int(m.group('H')) if m.group('H') else None\n",
    "        M = int(m.group('M')) if m.group('M') else None\n",
    "        S = int(m.group('S')) if m.group('S') else None\n",
    "        return None, None, None, H, M, S\n",
    "\n",
    "    return None, None, None, None, None, None\n",
    "\n",
    "def _ymd_to_weekday(y, m, d) -> Optional[int]:\n",
    "    if y is None or m is None or d is None:\n",
    "        return None\n",
    "    try:\n",
    "        return datetime(int(y), int(m), int(d)).weekday() + 1  # Monday=1 ... Sunday=7\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def _guess_publisher(soup: BeautifulSoup, text: str) -> str:\n",
    "    \"\"\"\n",
    "    Publisher 提取策略：\n",
    "    1) <meta property=\"og:site_name\" content=\"...\">\n",
    "    2) <meta name=\"publisher\" content=\"...\"> 或 <meta property=\"article:publisher\" ...>\n",
    "    3) 若页面里有 <link rel=\"canonical\" href=\"...\"> 或首个 <a href> 域名，取域名主体（如 nytimes, bbc）\n",
    "    \"\"\"\n",
    "    # og:site_name\n",
    "    tag = soup.find(\"meta\", attrs={\"property\": \"og:site_name\"})\n",
    "    if tag and tag.get(\"content\"):\n",
    "        return _clean(tag.get(\"content\"))\n",
    "\n",
    "    # name=publisher / property=article:publisher (Facebook often uses a URL here)\n",
    "    for key in [\"publisher\", \"article:publisher\"]:\n",
    "        tag = soup.find(\"meta\", attrs={\"name\": key}) or soup.find(\"meta\", attrs={\"property\": key})\n",
    "        if tag and tag.get(\"content\"):\n",
    "            val = tag.get(\"content\")\n",
    "            # 如果是 URL，提取域名主干\n",
    "            if re.match(r\"^https?://\", val, re.I):\n",
    "                try:\n",
    "                    netloc = urlparse(val).netloc\n",
    "                    base = netloc.split(\".\")\n",
    "                    core = base[-2] if len(base) >= 2 else netloc\n",
    "                    return _clean(core)\n",
    "                except Exception:\n",
    "                    pass\n",
    "            return _clean(val)\n",
    "\n",
    "    # canonical 或第一个 a[href] 的域名\n",
    "    link = soup.find(\"link\", rel=\"canonical\")\n",
    "    href = None\n",
    "    if link and link.get(\"href\"):\n",
    "        href = link.get(\"href\")\n",
    "    if not href:\n",
    "        a = soup.find(\"a\", href=True)\n",
    "        if a:\n",
    "            href = a.get(\"href\")\n",
    "\n",
    "    if href and re.match(r\"^https?://\", href, re.I):\n",
    "        try:\n",
    "            netloc = urlparse(href).netloc\n",
    "            base = netloc.split(\".\")\n",
    "            core = base[-2] if len(base) >= 2 else netloc\n",
    "            return _clean(core)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    return \"unknown\"\n",
    "\n",
    "def parse_html_like_model8_plus_publisher(html: str) -> Dict[str, Any]:\n",
    "    # 输出字段（完全覆盖 model8 的列 + 新增 Publisher）\n",
    "    # 'Title','Author','Channel','Topic','Publisher',\n",
    "    # 'Day','Date','Month','Year','Hour','Minute','Second',\n",
    "    # 'Content_Len','Num_See_Also','Num_Image','Num_A'\n",
    "    html = _s(html)\n",
    "    if not html:\n",
    "        return dict(\n",
    "            Title=\"unknown\", Author=\"unknown\", Channel=\"unknown\", Topic=\"unknown\", Publisher=\"unknown\",\n",
    "            Day=np.nan, Date=np.nan, Month=np.nan, Year=np.nan,\n",
    "            Hour=np.nan, Minute=np.nan, Second=np.nan,\n",
    "            Content_Len=0, Num_See_Also=0, Num_Image=0, Num_A=0\n",
    "        )\n",
    "\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    text = soup.get_text(\" \", strip=True)\n",
    "\n",
    "    # Title\n",
    "    title = _clean(soup.title.get_text(strip=True) if soup.title else \"\")\n",
    "\n",
    "    # Author：优先 meta[name=author]，再 author/byline 容器；清掉 'by ' 与时间串\n",
    "    author = \"\"\n",
    "    tag_author = soup.find(\"meta\", attrs={\"name\": re.compile(r\"author\", re.I)})\n",
    "    if tag_author and tag_author.get(\"content\"):\n",
    "        author = tag_author.get(\"content\", \"\")\n",
    "    if not author:\n",
    "        cand = soup.select('[class*=\"author\" i], [id*=\"author\" i], [class*=\"byline\" i]')\n",
    "        if cand:\n",
    "            author = cand[0].get_text(\" \", strip=True)\n",
    "    author = re.sub(r\"^\\s*by\\s+\", \"\", author, flags=re.I)\n",
    "    author = re.sub(r\"\\b\\d{4}-\\d{2}-\\d{2}.*$\", \"\", author).strip()\n",
    "    author = re.sub(r\"\\b(?:utc|gmt)\\b.*$\", \"\", author, flags=re.I).strip()\n",
    "    author = _clean(author)\n",
    "\n",
    "    # Channel：只采 data-channel 或明显 channel 容器的短文本\n",
    "    channel = \"\"\n",
    "    node = soup.find(attrs={\"data-channel\": True})\n",
    "    if node:\n",
    "        channel = node.get(\"data-channel\", \"\")\n",
    "    if not channel:\n",
    "        cand_ch = soup.select('[class*=\"channel\" i], [id*=\"channel\" i]')\n",
    "        if cand_ch:\n",
    "            tmp = (cand_ch[0].get(\"data-channel\") or cand_ch[0].get_text(\" \", strip=True) or \"\").strip()\n",
    "            if tmp and len(tmp) <= 64:\n",
    "                channel = tmp\n",
    "    channel = _clean(channel)\n",
    "\n",
    "    # Topic：从 data-topic 或典型话题列表容器聚合\n",
    "    topics = []\n",
    "    for node in soup.select(\"[data-topic]\"):\n",
    "        topics.append(_clean(node.get(\"data-topic\", \"\")))\n",
    "    if not topics:\n",
    "        for node in soup.select('footer [class*=\"topic\" i], [class*=\"article-topics\" i] a, [class*=\"article-topics\" i] li'):\n",
    "            t = _clean(node.get_text(\" \", strip=True))\n",
    "            if t != \"unknown\":\n",
    "                topics.append(t)\n",
    "    topics = [t for t in dict.fromkeys(topics) if t and t != \"unknown\"]\n",
    "    topic_str = \"topics: \" + \" , \".join(topics) if topics else \"unknown\"\n",
    "\n",
    "    # Publisher（新增）\n",
    "    publisher = _guess_publisher(soup, text)\n",
    "\n",
    "    # 时间：meta 优先，正则兜底\n",
    "    raw_dt = \"\"\n",
    "    for key in [\"article:published_time\", \"article:modified_time\", \"og:updated_time\", \"pubdate\", \"date\", \"publishdate\"]:\n",
    "        tag = soup.find(\"meta\", attrs={\"property\": key}) or soup.find(\"meta\", attrs={\"name\": key})\n",
    "        if tag and tag.get(\"content\"):\n",
    "            raw_dt = tag.get(\"content\")\n",
    "            break\n",
    "    if not raw_dt:\n",
    "        raw_dt = text\n",
    "\n",
    "    y, m, d, H, M, S = _first_datetime(raw_dt)\n",
    "    wk = _ymd_to_weekday(y, m, d)\n",
    "\n",
    "    # 统计\n",
    "    content_len   = len(text)\n",
    "    num_img       = len(soup.find_all(\"img\"))\n",
    "    num_a         = len(soup.find_all(\"a\"))\n",
    "    num_see_also  = len(re.findall(r\"\\bsee also\\b\", text, flags=re.I))\n",
    "\n",
    "    return dict(\n",
    "        Title=title,\n",
    "        Author=author,\n",
    "        Channel=channel,\n",
    "        Topic=topic_str,\n",
    "        Publisher=publisher,\n",
    "        Day=np.nan if wk is None else wk,\n",
    "        Date=np.nan if d is None else d,\n",
    "        Month=np.nan if m is None else m,\n",
    "        Year=np.nan if y is None else y,\n",
    "        Hour=np.nan if H is None else H,\n",
    "        Minute=np.nan if M is None else M,\n",
    "        Second=np.nan if S is None else S,\n",
    "        Content_Len=content_len,\n",
    "        Num_See_Also=num_see_also,\n",
    "        Num_Image=num_img,\n",
    "        Num_A=num_a\n",
    "    )\n",
    "\n",
    "def html_to_table(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    rows = [parse_html_like_model8_plus_publisher(s) for s in df[\"Page content\"].astype(str).tolist()]\n",
    "    meta = pd.DataFrame(rows, index=df.index)\n",
    "    meta.insert(0, \"Id\", df[\"Id\"].values)\n",
    "    return meta\n",
    "\n",
    "meta_train_raw = html_to_table(df_train)\n",
    "meta_test_raw  = html_to_table(df_test)\n",
    "\n",
    "# 快速查看\n",
    "meta_train_raw.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8aeb2470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique y after mapping: [0 1]\n",
      "X shapes: (27643, 16) (11847, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Channel</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Day</th>\n",
       "      <th>Date</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>Second</th>\n",
       "      <th>Content_Len</th>\n",
       "      <th>Num_See_Also</th>\n",
       "      <th>Num_Image</th>\n",
       "      <th>Num_A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unknown</td>\n",
       "      <td>clara moskowitz</td>\n",
       "      <td>world</td>\n",
       "      <td>topics: asteroid , asteroids , challenge , ear...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>2013</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3787</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unknown</td>\n",
       "      <td>christina warren</td>\n",
       "      <td>tech</td>\n",
       "      <td>topics: apps and software , google , open sour...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>2013</td>\n",
       "      <td>17.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2081</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unknown</td>\n",
       "      <td>sam laird</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>topics: entertainment , nfl , nfl draft , spor...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2014</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6761</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Title            Author        Channel  \\\n",
       "0  unknown   clara moskowitz          world   \n",
       "1  unknown  christina warren           tech   \n",
       "2  unknown         sam laird  entertainment   \n",
       "\n",
       "                                               Topic Publisher  Day  Date  \\\n",
       "0  topics: asteroid , asteroids , challenge , ear...   unknown    3    19   \n",
       "1  topics: apps and software , google , open sour...   unknown    4    28   \n",
       "2  topics: entertainment , nfl , nfl draft , spor...   unknown    3     7   \n",
       "\n",
       "   Month  Year  Hour  Minute  Second  Content_Len  Num_See_Also  Num_Image  \\\n",
       "0      6  2013  15.0     4.0    30.0         3787             4          1   \n",
       "1      3  2013  17.0    40.0    55.0         2081             1          2   \n",
       "2      5  2014  19.0    15.0    20.0         6761             1          2   \n",
       "\n",
       "   Num_A  \n",
       "0     22  \n",
       "1     18  \n",
       "2     11  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================\n",
    "# Cell 4 — Clean & Select (keep all model8 features + Author + Publisher)\n",
    "# =============================================\n",
    "\n",
    "# 文本列（在 model8 基础上新增 Author、Publisher）\n",
    "text_cols = [\"Title\", \"Author\", \"Channel\", \"Topic\", \"Publisher\"]\n",
    "\n",
    "# 数值列（model8）\n",
    "num_cols_model8 = [\n",
    "    \"Day\",\"Date\",\"Month\",\"Year\",\"Hour\",\"Minute\",\"Second\",\n",
    "    \"Content_Len\",\"Num_See_Also\",\"Num_Image\",\"Num_A\"\n",
    "]\n",
    "\n",
    "# 合并统一做缺失/类型处理后再切回\n",
    "all_df = pd.concat([\n",
    "    meta_train_raw.assign(_is_train=1),\n",
    "    meta_test_raw.assign(_is_train=0)\n",
    "], axis=0, ignore_index=True)\n",
    "\n",
    "# 文本缺失填充\n",
    "for c in text_cols:\n",
    "    all_df[c] = all_df[c].fillna(\"unknown\").astype(str)\n",
    "\n",
    "# 数值转数值（保留 NaN，稍后 SimpleImputer 处理）\n",
    "for c in num_cols_model8:\n",
    "    all_df[c] = pd.to_numeric(all_df[c], errors=\"coerce\")\n",
    "\n",
    "meta_train = all_df[all_df[\"_is_train\"]==1].drop(columns=[\"_is_train\"]).reset_index(drop=True)\n",
    "meta_test  = all_df[all_df[\"_is_train\"]==0].drop(columns=[\"_is_train\"]).reset_index(drop=True)\n",
    "\n",
    "X_train_base = meta_train[text_cols + num_cols_model8].copy()\n",
    "X_test_base  = meta_test[text_cols + num_cols_model8].copy()\n",
    "y = df_train[\"Popularity\"].values\n",
    "\n",
    "# 统一标签到 {0,1}\n",
    "y = pd.Series(y).map({-1: 0, 0: 0, 1: 1}).astype(int).values\n",
    "print(\"Unique y after mapping:\", np.unique(y))\n",
    "\n",
    "\n",
    "print(\"X shapes:\", X_train_base.shape, X_test_base.shape)\n",
    "X_train_base.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fcb5e738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================\n",
    "# Cell 5 — ColumnTransformer（5 文本 + 数值 with imputer）\n",
    "# =============================================\n",
    "from sklearn.pipeline import Pipeline as SkPipe  # 仅用于数值子流水线\n",
    "\n",
    "# 与 Cell 4 保持一致的列\n",
    "numeric_cols = num_cols_model8  # 只用 model8 的数值列\n",
    "# 文本列在 ColumnTransformer 中逐一指定\n",
    "\n",
    "# 数值列填充：避免 RF 因 NaN 报错\n",
    "numeric_transformer = SkPipe(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=0.0)),\n",
    "])\n",
    "\n",
    "# 五个文本列分别做 BOW（适度限维 & 过滤低频）\n",
    "title_bow     = (\"title_bow\",     CountVectorizer(lowercase=True, min_df=3, max_features=2**14), \"Title\")\n",
    "author_bow    = (\"author_bow\",    CountVectorizer(lowercase=True, min_df=3, max_features=2**13), \"Author\")\n",
    "channel_bow   = (\"channel_bow\",   CountVectorizer(lowercase=True, min_df=3, max_features=2**12), \"Channel\")\n",
    "topic_bow     = (\"topic_bow\",     CountVectorizer(lowercase=True, min_df=3, max_features=2**14), \"Topic\")\n",
    "publisher_bow = (\"publisher_bow\", CountVectorizer(lowercase=True, min_df=2, max_features=2**12), \"Publisher\")\n",
    "\n",
    "trans_all = ColumnTransformer(\n",
    "    transformers=[\n",
    "        title_bow,\n",
    "        author_bow,\n",
    "        channel_bow,\n",
    "        topic_bow,\n",
    "        publisher_bow,\n",
    "        (\"num\", numeric_transformer, numeric_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",        # 只保留上面列，避免意外列混入\n",
    "    sparse_threshold=0.3     # 输出为稀疏矩阵（高维 BOW 更省内存）\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c6c9102c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================\n",
    "# Cell 6 — Base model builders (mimic model8 style)\n",
    "# =============================================\n",
    "\n",
    "def make_rf():\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=400,\n",
    "        max_depth=None,\n",
    "        n_jobs=-1,\n",
    "        random_state=RANDOM_STATE,\n",
    "        class_weight=\"balanced_subsample\"\n",
    "    )\n",
    "    return Pipeline([(\"prep\", trans_all), (\"clf\", rf)])\n",
    "\n",
    "def make_lgbm():\n",
    "    lgbm = LGBMClassifier(\n",
    "        n_estimators=600,\n",
    "        learning_rate=0.02,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.9,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1,\n",
    "        objective=\"binary\",\n",
    "        metric=\"auc\",\n",
    "    )\n",
    "    return Pipeline([(\"prep\", trans_all), (\"clf\", lgbm)])\n",
    "\n",
    "def make_xgb():\n",
    "    xgb = XGBClassifier(\n",
    "        n_estimators=600,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        max_depth=6,\n",
    "        min_child_weight=2.0,\n",
    "        reg_alpha=0.0,\n",
    "        reg_lambda=1.0,\n",
    "        eval_metric=\"auc\",\n",
    "        n_jobs=-1,\n",
    "        random_state=RANDOM_STATE,\n",
    "        tree_method=\"hist\"\n",
    "    )\n",
    "    return Pipeline([(\"prep\", trans_all), (\"clf\", xgb)])\n",
    "\n",
    "def make_cat():\n",
    "    cat = CatBoostClassifier(\n",
    "        depth=6,\n",
    "        learning_rate=0.06,\n",
    "        n_estimators=800,\n",
    "        l2_leaf_reg=6.0,\n",
    "        random_seed=RANDOM_STATE,\n",
    "        loss_function=\"Logloss\",\n",
    "        eval_metric=\"AUC\",\n",
    "        verbose=False,\n",
    "    )\n",
    "    return Pipeline([(\"prep\", trans_all), (\"clf\", cat)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d2b1ffea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================\n",
    "# Cell 7 — CV helpers\n",
    "# =============================================\n",
    "\n",
    "def train_one(pipe: Pipeline, X: pd.DataFrame, y: np.ndarray, name: str = \"model\"):\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "    scoring = \"roc_auc\"\n",
    "    cvres = cross_validate(\n",
    "        pipe, X, y,\n",
    "        cv=cv,\n",
    "        scoring=scoring,\n",
    "        return_train_score=True,\n",
    "        n_jobs=1\n",
    "    )\n",
    "    print(json.dumps({\n",
    "        \"name\": name,\n",
    "        \"cv_train_auc_mean\": float(np.mean(cvres[\"train_score\"])),\n",
    "        \"cv_train_auc_std\":  float(np.std(cvres[\"train_score\"])),\n",
    "        \"cv_val_auc_mean\":   float(np.mean(cvres[\"test_score\"])),\n",
    "        \"cv_val_auc_std\":    float(np.std(cvres[\"test_score\"])),\n",
    "    }, ensure_ascii=False, indent=2))\n",
    "\n",
    "    # Holdout\n",
    "    X_tr, X_va, y_tr, y_va = train_test_split(\n",
    "        X, y, test_size=0.15, random_state=RANDOM_STATE, stratify=y\n",
    "    )\n",
    "    pipe.fit(X_tr, y_tr)\n",
    "    proba = pipe.predict_proba(X_va)[:, 1]\n",
    "    auc  = roc_auc_score(y_va, proba)\n",
    "    print(f\"[Holdout] {name} AUC = {auc:.4f}\")\n",
    "    return pipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b8a1b8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"RF\",\n",
      "  \"cv_train_auc_mean\": 1.0,\n",
      "  \"cv_train_auc_std\": 0.0,\n",
      "  \"cv_val_auc_mean\": 0.5841340850938112,\n",
      "  \"cv_val_auc_std\": 0.00505939946386798\n",
      "}\n",
      "[Holdout] RF AUC = 0.5814\n",
      "[Holdout] RF AUC = 0.5814\n",
      "[LightGBM] [Info] Number of positive: 10906, number of negative: 11208\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049178 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3666\n",
      "[LightGBM] [Info] Number of data points in the train set: 22114, number of used features: 1155\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.493172 -> initscore=-0.027315\n",
      "[LightGBM] [Info] Start training from score -0.027315\n",
      "[LightGBM] [Info] Number of positive: 10906, number of negative: 11208\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049178 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3666\n",
      "[LightGBM] [Info] Number of data points in the train set: 22114, number of used features: 1155\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.493172 -> initscore=-0.027315\n",
      "[LightGBM] [Info] Start training from score -0.027315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\11958\\.conda\\envs\\news_pred\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\11958\\.conda\\envs\\news_pred\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\11958\\.conda\\envs\\news_pred\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 10905, number of negative: 11209\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028739 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3664\n",
      "[LightGBM] [Info] Number of data points in the train set: 22114, number of used features: 1153\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.493127 -> initscore=-0.027496\n",
      "[LightGBM] [Info] Start training from score -0.027496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\11958\\.conda\\envs\\news_pred\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\11958\\.conda\\envs\\news_pred\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\11958\\.conda\\envs\\news_pred\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 10905, number of negative: 11209\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037086 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3683\n",
      "[LightGBM] [Info] Number of data points in the train set: 22114, number of used features: 1163\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.493127 -> initscore=-0.027496\n",
      "[LightGBM] [Info] Start training from score -0.027496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\11958\\.conda\\envs\\news_pred\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\11958\\.conda\\envs\\news_pred\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\11958\\.conda\\envs\\news_pred\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 10906, number of negative: 11209\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021528 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3670\n",
      "[LightGBM] [Info] Number of data points in the train set: 22115, number of used features: 1151\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.493149 -> initscore=-0.027404\n",
      "[LightGBM] [Info] Start training from score -0.027404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\11958\\.conda\\envs\\news_pred\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\11958\\.conda\\envs\\news_pred\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\11958\\.conda\\envs\\news_pred\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 10906, number of negative: 11209\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050693 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3687\n",
      "[LightGBM] [Info] Number of data points in the train set: 22115, number of used features: 1165\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.493149 -> initscore=-0.027404\n",
      "[LightGBM] [Info] Start training from score -0.027404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\11958\\.conda\\envs\\news_pred\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\11958\\.conda\\envs\\news_pred\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\11958\\.conda\\envs\\news_pred\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"LGBM\",\n",
      "  \"cv_train_auc_mean\": 0.7931560795748053,\n",
      "  \"cv_train_auc_std\": 0.0038484736413856627,\n",
      "  \"cv_val_auc_mean\": 0.5879211432218467,\n",
      "  \"cv_val_auc_std\": 0.010913289496506608\n",
      "}\n",
      "[LightGBM] [Info] Number of positive: 11587, number of negative: 11909\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.054241 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3844\n",
      "[LightGBM] [Info] Number of data points in the train set: 23496, number of used features: 1217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.493148 -> initscore=-0.027411\n",
      "[LightGBM] [Info] Start training from score -0.027411\n",
      "[LightGBM] [Info] Number of positive: 11587, number of negative: 11909\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.054241 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3844\n",
      "[LightGBM] [Info] Number of data points in the train set: 23496, number of used features: 1217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.493148 -> initscore=-0.027411\n",
      "[LightGBM] [Info] Start training from score -0.027411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\11958\\.conda\\envs\\news_pred\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Holdout] LGBM AUC = 0.5765\n",
      "{\n",
      "  \"name\": \"XGB\",\n",
      "  \"cv_train_auc_mean\": 0.8098966267202515,\n",
      "  \"cv_train_auc_std\": 0.002493867059203662,\n",
      "  \"cv_val_auc_mean\": 0.5875622469160587,\n",
      "  \"cv_val_auc_std\": 0.007337565189395578\n",
      "}\n",
      "{\n",
      "  \"name\": \"XGB\",\n",
      "  \"cv_train_auc_mean\": 0.8098966267202515,\n",
      "  \"cv_train_auc_std\": 0.002493867059203662,\n",
      "  \"cv_val_auc_mean\": 0.5875622469160587,\n",
      "  \"cv_val_auc_std\": 0.007337565189395578\n",
      "}\n",
      "[Holdout] XGB AUC = 0.5775\n",
      "[Holdout] XGB AUC = 0.5775\n",
      "{\n",
      "  \"name\": \"CatBoost\",\n",
      "  \"cv_train_auc_mean\": 0.7929363309555538,\n",
      "  \"cv_train_auc_std\": 0.003405093136667055,\n",
      "  \"cv_val_auc_mean\": 0.5894721098788737,\n",
      "  \"cv_val_auc_std\": 0.012503460200810798\n",
      "}\n",
      "{\n",
      "  \"name\": \"CatBoost\",\n",
      "  \"cv_train_auc_mean\": 0.7929363309555538,\n",
      "  \"cv_train_auc_std\": 0.003405093136667055,\n",
      "  \"cv_val_auc_mean\": 0.5894721098788737,\n",
      "  \"cv_val_auc_std\": 0.012503460200810798\n",
      "}\n",
      "[Holdout] CatBoost AUC = 0.5804\n",
      "[Holdout] CatBoost AUC = 0.5804\n"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# Cell 8 — Train base models\n",
    "# =============================================\n",
    "rf_pipe  = train_one(make_rf(),   X_train_base, y, name=\"RF\")\n",
    "lgb_pipe = train_one(make_lgbm(), X_train_base, y, name=\"LGBM\")\n",
    "xgb_pipe = train_one(make_xgb(),  X_train_base, y, name=\"XGB\")\n",
    "cat_pipe = train_one(make_cat(),  X_train_base, y, name=\"CatBoost\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0b2ca922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 11587, number of negative: 11909\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047967 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3844\n",
      "[LightGBM] [Info] Number of data points in the train set: 23496, number of used features: 1217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.493148 -> initscore=-0.027411\n",
      "[LightGBM] [Info] Start training from score -0.027411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\11958\\.conda\\envs\\news_pred\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Holdout] Voting AUC = 0.5782\n",
      "Saved voting model to: output\\voting_model9_mimic_model8_plus_author_publisher.pkl\n",
      "Saved voting model to: output\\voting_model9_mimic_model8_plus_author_publisher.pkl\n"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# Cell 9 — Weighted soft voting + save\n",
    "# =============================================\n",
    "voting = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"lgbm\", make_lgbm()),\n",
    "        (\"forest\", make_rf()),\n",
    "        (\"catboost\", make_cat()),\n",
    "        (\"xgboost\", make_xgb()),\n",
    "    ],\n",
    "    voting=\"soft\",\n",
    "    weights=[1.0, 0.05, 0.05, 0.10],  # mimic model8：LGBM 主力，其它轻权纠错\n",
    "    n_jobs=None\n",
    ")\n",
    "\n",
    "# quick holdout check\n",
    "X_tr, X_va, y_tr, y_va = train_test_split(\n",
    "    X_train_base, y, test_size=0.15, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "voting.fit(X_tr, y_tr)\n",
    "proba_va = voting.predict_proba(X_va)[:, 1]\n",
    "print(f\"[Holdout] Voting AUC = {roc_auc_score(y_va, proba_va):.4f}\")\n",
    "\n",
    "# —— 使用标准 pickle 保存（_pickle 没有 HIGHEST_PROTOCOL）——\n",
    "import pickle\n",
    "\n",
    "with open(MODEL_PATH, \"wb\") as f:\n",
    "    pickle.dump(voting, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(\"Saved voting model to:\", MODEL_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b642732b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 13632, number of negative: 14011\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.064642 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4271\n",
      "[LightGBM] [Info] Number of data points in the train set: 27643, number of used features: 1378\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.493145 -> initscore=-0.027423\n",
      "[LightGBM] [Info] Start training from score -0.027423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\11958\\.conda\\envs\\news_pred\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved to: output\\submission_model9_mimic_model8_plus_author_publisher.csv\n"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# Cell 10 — Fit on full train & predict test\n",
    "# =============================================\n",
    "voting_full = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"lgbm\", make_lgbm()),\n",
    "        (\"forest\", make_rf()),\n",
    "        (\"catboost\", make_cat()),\n",
    "        (\"xgboost\", make_xgb()),\n",
    "    ],\n",
    "    voting=\"soft\",\n",
    "    weights=[1.0, 0.05, 0.05, 0.10],\n",
    "    n_jobs=None\n",
    ")\n",
    "voting_full.fit(X_train_base, y)\n",
    "\n",
    "# 保险拿到“正类=1”的概率索引\n",
    "pos_idx = int(np.where(voting_full.classes_ == 1)[0][0])\n",
    "test_proba = voting_full.predict_proba(X_test_base)[:, pos_idx]\n",
    "\n",
    "sub = pd.DataFrame({\"Id\": df_test[\"Id\"], \"Popularity\": test_proba})\n",
    "sub.to_csv(SUB_PATH, index=False)\n",
    "print(\"Submission saved to:\", SUB_PATH)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "news_pred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
